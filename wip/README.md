## Routine/WIP

A lightweight scraper that automates extracting table data from local or remote HTML pages.

### Source

All main script files are located in the `src` directory. Feel free to explore or modify them.

### Driver

To run the script properly, we'll need a ChromeDriver version that matches with our Chrome browser version.  
We can download a compatible version here::  
[Github](https://github.com/GoogleChromeLabs/chrome-for-testing) or [the web](googlechromelabs.github.io/chrome-for-testing/).

### Data

The output files generated by the script will be stored in the `data` directory.

### Usage

1. Clone the repository.
2. Create a `.env` file by copying the example:  
   `cp .env.example .env`
3. Install dependencies:  
   `pip install -r requirements.txt`
4. Configure your environment variables in the `.env` file.
5. Run the scraper:  
   `python src/filling.py` or `python src/loss.py` or even `python src/komponen.py`
