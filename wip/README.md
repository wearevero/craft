## Routine/WIP

A lightweight scraper that automates extracting table data from local or remote HTML pages.

### Source

All main script files are located in the `src` directory. Feel free to explore or modify them.

### Driver

To run the script properly, you'll need a ChromeDriver version that matches your Chrome browser version.  
We provide a default version that works for us, but if your Chrome browser version is different, you can download a compatible one here:  
[https://github.com/dreamshao/chromedriver](https://github.com/dreamshao/chromedriver)

### Data

The output files generated by the script will be stored in the `data` directory.

### Usage

1. Clone the repository.
2. Create a `.env` file by copying the example:  
   `cp .env.example .env`
3. Install dependencies:  
   `pip install -r requirements.txt`
4. Configure your environment variables in the `.env` file.
5. Run the scraper:  
   `python src/filling.py` or `python src/loss.py` or even `python src/komponen.py`
